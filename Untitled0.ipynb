{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNS4seq7cnXTAp0lmTN5jIW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricBritto14/Pytorch/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfwD8Y9KF8aR",
        "outputId": "f47de196-a676-4d8c-a6e0-0749ce1fd5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.float32\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.float32\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "[[3, 2, 6], [6, 5, 3]]\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[-0.7446, -1.6808, -0.6879],\n",
            "        [-1.5387, -2.1166,  1.5676],\n",
            "        [ 0.1213,  0.8827, -0.1514]])\n",
            "[[-0.74457914 -1.6808296  -0.68786734]\n",
            " [-1.5386755  -2.1166494   1.5675832 ]\n",
            " [ 0.12132929  0.8827429  -0.15141842]]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([-10.0000,   1.5676,  -0.1514])\n",
            "tensor(-10.)\n",
            "tensor([[[ 0.2589,  0.6790,  0.1147],\n",
            "         [-1.1771, -0.1148, -0.0380]],\n",
            "\n",
            "        [[-0.7940,  0.5551, -1.0965],\n",
            "         [-0.8210,  1.1548,  0.5510]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[ 0.2589,  0.6790,  0.1147, -1.1771, -0.1148, -0.0380],\n",
            "        [-0.7940,  0.5551, -1.0965, -0.8210,  1.1548,  0.5510]])\n",
            "cuda\n",
            "tensor([[ 0.2589,  0.6790,  0.1147, -1.1771, -0.1148, -0.0380],\n",
            "        [-0.7940,  0.5551, -1.0965, -0.8210,  1.1548,  0.5510]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#Por boas praticar, verificar se a GPU ta disponivel na hora de começar\n",
        "ppp = torch.randn(10)\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(device)\n",
        "\n",
        "tns = tns.to(device)\n",
        "print(tns)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "lista = [[1, 2, 3],\n",
        "          [4, 5, 6]]\n",
        "\n",
        "#torch.tensor para transformar a lista em tensores\n",
        "#torch.FloatTensor para na hora de mostrar no print, os valores da lista já serem transformados em tensores floats, como por exemplo 1. 2.\n",
        "tns = torch.FloatTensor(lista)\n",
        "print(tns.dtype) #tns.dtype para ele mostrar se o float do tensor é 32, 64... e etc\n",
        "print(tns)\n",
        "\n",
        "#Double para mais precisão com números double\n",
        "tns2 = torch.DoubleTensor(lista)\n",
        "print(tns.dtype)\n",
        "print(tns)\n",
        "\n",
        "#Long seria para ligar com números inteiros com mais precisão\n",
        "tns3 = torch.LongTensor(lista)\n",
        "print(tns.dtype)\n",
        "print(tns)\n",
        "\n",
        "#Outra forma de instanciar tensores com arrays(matrizes) numpy(do próprio python)\n",
        "#.from_numphy preserva o tipo original da array na hora de transformar pra tensor, se o array for 32, 64, o tensor também será\n",
        "arr = [[3, 2, 6],\n",
        "       [6, 5, 3]]\n",
        "#tns = torch.from_numpy(arr)\n",
        "\n",
        "print(arr)\n",
        "#print(arr.dtype)\n",
        "\n",
        "#print(tns)\n",
        "#print(tns.dtype)\n",
        "\n",
        "#Tensores inicializados, com valores de 1, 0 e random\n",
        "tns1 = torch.ones(2,3)\n",
        "tns0 = torch.zeros(4, 5)\n",
        "tnsr = torch.randn(3, 3)\n",
        "\n",
        "print(tns1)\n",
        "print(tns0)\n",
        "print(tnsr)\n",
        "\n",
        "#Transformando devolta de tensor para array(matriz) com o numpy\n",
        "arr = tnsr.data.numpy()\n",
        "print(arr)\n",
        "print(type(arr))\n",
        "\n",
        "#Indexização em tensor, no caso indexizar seria mexer no tensor em respectivos \"slots\" do mesmo\n",
        "tnsr[0, 2] = -10 #Fazendo uma indexazação com alteração na linha 0 e coluna 2, para -10 no valor que estiver lá\n",
        "print(tnsr[:, 2]) #Fazendo uma indexazação para mostrar todas as de zero até antes do 2\n",
        "print(tnsr[0,2]) #Acessando todas os valores da coluna 2, na linha 0\n",
        "\n",
        "#As operações com tensores, são feitas que nem o python normal, com +, -, *, / ... porém os tensores fazem a operação uma com a outra, por exemplo o index 1 de um tensor com o index 1 do outro tensor\n",
        "#As operações são feitas ponto a ponto, então os dois tensores tem que ser das mesmas dimensões\n",
        "\n",
        "#Para saber as dimensões de um tensor aleatório, tem o metodo do prórprio pytorch que seria o .size() ou tem a do próprio python o .shape()\n",
        "tns = torch.randn(2,2,3)\n",
        "print(tns)\n",
        "\n",
        "print(tns.size())\n",
        "\n",
        "#O .view seria para \"achatar\" e modificar a visualização do tensor, por exemplo do tns criado, invez de ser 2 linhas, 2 separações de matrizes, e 3 colunas, com o view usando o -1 para achatar, ficaria tudo em 1 ou 2 linhas só\n",
        "tns = tns.view(tns.size(0), -1) #Quando você não sabe as dimensões do tensor e quer redimensionar, você pode manter a 1 dimensão no caso 2 linhas usando o \"0\" e dps pedir para achatar o resto usando o -1\n",
        "print(tns)\n",
        "\n",
        "#Por boas praticar, verificar se a GPU ta disponivel\n",
        "ppp = torch.randn(10)\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(device)\n",
        "\n",
        "tns = tns.to(device)\n",
        "print(tns)\n",
        "\n",
        "\n",
        "#Contatenação de tensores da mesma dimensão\n",
        "tns_out = torch.cat( (tns1, tns2), dim=0 )\n",
        "#torch.squeeze() e torch.unsqueeze() que, respectivamente, removem e adicionam dimensões de tamanho 1\n",
        "\n"
      ]
    }
  ]
}